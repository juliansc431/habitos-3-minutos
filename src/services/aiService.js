// aiService.js â€” REST directo a Gemini API (sin SDK, compatible con gemini-3-flash-preview)
// v6.0 â€” Direct REST, no SDK dependency

const SYSTEM_PROMPT = `Eres el "Coach de Micro-HÃ¡bitos Express", un asistente motivador y directo.

REGLA DE RESPUESTA:
- Responde en mÃ¡ximo 3-4 oraciones. Nunca mÃ¡s.
- Para saludos ("hola"): Una bienvenida breve y UNA pregunta. Sin listas.
- Cuando el usuario pida un hÃ¡bito: DescrÃ­belo brevemente y haz una pregunta de seguimiento.
- Usa 1-2 emojis por respuesta (âš¡, ðŸ§ , ðŸ’Ž).
- NO uses negritas, listas numeradas ni subtÃ­tulos.
- La app se llama "HÃ¡bitos 3 Minutos" (los usuarios ganan XP y Cristales).`;

const GEMINI_MODEL = "gemini-3-flash-preview";
const API_BASE = "https://generativelanguage.googleapis.com/v1beta/models";

export const chatWithCoach = async (userMessage, history = []) => {
    const rawKey = import.meta.env.VITE_GEMINI_API_KEY;
    const apiKey = rawKey ? rawKey.trim() : null;

    if (!apiKey) throw new Error("Llave API no configurada en Vercel.");
    if (!apiKey.startsWith("AIza")) throw new Error("Llave API invÃ¡lida.");

    // Build conversation history for the API
    const contents = [];

    // Add system context as first user turn (Gemini 1.x style)
    contents.push({
        role: "user",
        parts: [{ text: SYSTEM_PROMPT + "\n\nConfirma con 'ENTENDIDO'." }]
    });
    contents.push({
        role: "model",
        parts: [{ text: "ENTENDIDO. Â¿En quÃ© hÃ¡bito trabajamos hoy? ðŸ’Ž" }]
    });

    // Add conversation history (skip the first welcome message)
    for (let i = 1; i < history.length; i++) {
        const msg = history[i];
        contents.push({
            role: msg.role === "assistant" ? "model" : "user",
            parts: [{ text: msg.content }]
        });
    }

    // Add current user message
    contents.push({
        role: "user",
        parts: [{ text: userMessage }]
    });

    const url = `${API_BASE}/${GEMINI_MODEL}:generateContent?key=${apiKey}`;

    const response = await fetch(url, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
            contents,
            generationConfig: {
                maxOutputTokens: 400,
                temperature: 0.7,
            }
        })
    });

    if (!response.ok) {
        const errData = await response.json().catch(() => ({}));
        const errMsg = errData?.error?.message || `HTTP ${response.status}`;
        throw new Error(`API Error: ${errMsg}`);
    }

    const data = await response.json();
    const text = data?.candidates?.[0]?.content?.parts?.[0]?.text;

    if (!text) throw new Error("Respuesta vacÃ­a del modelo.");

    return text;
};
